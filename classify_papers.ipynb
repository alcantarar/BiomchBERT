{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"classify_papers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XJG5shp08CGC"},"source":["Uses Fine-Tuned BERT network to classify biomechanics papers from PubMed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnZ8CI-rwNOY","executionInfo":{"status":"ok","timestamp":1647197362305,"user_tz":420,"elapsed":435,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"9ce7ae88-f7c4-491a-dc24-09d6167ea8b5"},"source":["# Check date\n","!rm /etc/localtime\n","!ln -s /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\n","!date\n","# might need to restart runtime if timezone didn't change"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar 13 11:49:20 PDT 2022\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6klLdde-78nI","executionInfo":{"status":"ok","timestamp":1647197498643,"user_tz":420,"elapsed":54158,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"b7346778-d821-4b81-e8d5-79bfc21a69ee"},"source":["## Install & load libraries\n","\n","!pip install tensorflow==2.7.0\n","\n","try:\n","  from official.nlp import optimization\n","except:\n","  !pip install -q -U tf-models-official==2.4.0\n","  from official.nlp import optimization\n","try:\n","  from Bio import Entrez\n","except:\n","  !pip install -q -U biopython\n","  from Bio import Entrez\n","try:\n","  import tensorflow_text as text\n","except:\n","  !pip install -q -U tensorflow_text==2.7.3\n","  import tensorflow_text as text\n"," \n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import tensorflow as tf  # probably have to lock version\n","import string\n","import datetime\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","import tensorflow_hub as hub\n","from google.colab import drive\n","import datetime as dt\n","\n","#Define date range\n","today = dt.date.today()\n","yesterday = today - dt.timedelta(days=1)\n","week_ago = yesterday - dt.timedelta(days=7)  # ensure overlap in pubmed search\n","days_ago_6 = yesterday - dt.timedelta(days=6) # for text output\n","\n","# Mount Google Drive for model and csv up/download\n","drive.mount('/content/gdrive')\n","print(today)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.1 MB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 2.9 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 36.7 MB/s \n","\u001b[K     |████████████████████████████████| 234 kB 25.2 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 864 kB/s \n","\u001b[K     |████████████████████████████████| 596 kB 35.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 26.8 MB/s \n","\u001b[K     |████████████████████████████████| 47.8 MB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 31.0 MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.3 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n","\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Mounted at /content/gdrive\n","2022-03-13\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaSczx4IuQ0Y","executionInfo":{"status":"ok","timestamp":1647197566630,"user_tz":420,"elapsed":63605,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"5793b99a-0b8c-4dce-b79c-2078a5cbbc70"},"source":["# Define Search Criteria ----\n","def search(query):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.esearch(db='pubmed',\n","                            sort='most recent',\n","                            retmax='5000',\n","                            retmode='xml',\n","                            datetype='pdat',  # pdat is published date, edat is entrez date. \n","                            # reldate=7,  # only within n days from now\n","                            mindate= min_date,\n","                            maxdate= max_date,  # for searching date range\n","                            term=query)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Perform Search and Pull Paper Titles ----\n","def fetch_details(ids):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.efetch(db='pubmed',\n","                           retmode='xml',\n","                           id=ids)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Make the stop words for string cleaning ----\n","def html_strip(text):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.replace('[','').replace(']','')\n","    return text\n","\n","def clean_str(text, stops):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.split()\n","    return ' '.join([word for word in text if word not in stops])\n","\n","stop = list(stopwords.words('english'))\n","stop_c = [string.capwords(word) for word in stop]\n","for word in stop_c:\n","    stop.append(word)\n","\n","new_stop = ['The', 'An', 'A', 'Do', 'Is', 'In', 'StringElement', \n","            'NlmCategory', 'Label', 'attributes', 'INTRODUCTION',\n","            'METHODS', 'BACKGROUND', 'RESULTS', 'CONCLUSIONS']\n","for s in new_stop:\n","    stop.append(s)\n","\n","# Search terms (can test string with Pubmed Advanced Search) ----\n","# search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n","min_date = week_ago.strftime('%m/%d/%Y')\n","max_date = yesterday.strftime('%m/%d/%Y')\n","search_results = search('(biomech*[Title/Abstract] OR locomot*[Title/Abstract] NOT opiod*[Title/Abstract] NOT pharm*[Journal] NOT mouse[Title/Abstract] NOT drosophil*[Title/Abstract] NOT mice[Title/Abstract] NOT rats*[Title/Abstract] NOT elegans[Title/Abstract])')\n","id_list = search_results['IdList']\n","papers = fetch_details(id_list)\n","print(len(papers['PubmedArticle']), 'Papers found')\n","\n","titles, full_titles, keywords, authors, links, journals, abstracts = ([] for i in range(7))\n","\n","for paper in papers['PubmedArticle']:\n","    # clean and store titles, abstracts, and links\n","    t = clean_str(paper['MedlineCitation']['Article']['ArticleTitle'], \n","                  stop).replace('[','').replace(']','').capitalize()  # rm brackets that survived beautifulsoup, sentence case\n","    titles.append(t)\n","    full_titles.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n","    pmid = paper['MedlineCitation']['PMID']\n","    links.append('[URL=\"https://www.ncbi.nlm.nih.gov/pubmed/{0}\"]{1}[/URL]'.format(pmid, html_strip(paper['MedlineCitation']['Article']['ArticleTitle'])))\n","    try:\n","        abstracts.append(clean_str(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0], \n","                                    stop).replace('[','').replace(']','').capitalize())  # rm brackets that survived beautifulsoup, sentence case\n","    except:\n","        abstracts.append('')\n","\n","    # clean and store authors\n","    auths = []\n","    try:\n","        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n","            try:  # see if there is a last name and initials\n","                auth_name = [auth['LastName'], auth['Initials'] + ',']\n","                auth_name = ' '.join(auth_name)\n","                auths.append(auth_name)\n","            except:\n","                if 'LastName' in auth.keys():  # maybe they don't have initials\n","                    auths.append(auth['LastName'] + ',')\n","                else:  # no last name\n","                    auths.append('')\n","                    print(paper['MedlineCitation']['Article']['ArticleTitle'],\n","                          'has an issue with an author name:')\n","\n","    except:\n","        auths.append('AUTHOR NAMES ERROR')\n","        print(paper['MedlineCitation']['Article']['ArticleTitle'], 'has no author list?')\n","    # compile authors\n","    authors.append(' '.join(auths).replace('[','').replace(']',''))  # rm brackets in names\n","    # journal names\n","    journals.append(paper['MedlineCitation']['Article']['Journal']['Title'].replace('[','').replace(']',''))  # rm brackets\n","\n","    # store keywords \n","    if paper['MedlineCitation']['KeywordList'] != []:\n","        kwds = []\n","        for kw in paper['MedlineCitation']['KeywordList'][0]:\n","            kwds.append(kw[:])\n","        keywords.append(', '.join(kwds).lower())\n","    else:\n","      keywords.append('')\n","\n","# Put Titles, Abstracts, Authors, Journal, and Keywords into dataframe\n","papers_df = pd.DataFrame({'title': titles,\n","                          'keywords': keywords,\n","                          'abstract': abstracts,\n","                          'authors': authors,\n","                          'journal': journals,\n","                          'links': links,\n","                          'raw_title': full_titles,\n","                          'mindate': min_date,\n","                          'maxdate': max_date})\n","\n","\n","# remove papers with no title or no authors\n","for index, row in papers_df.iterrows():\n","    if row['title'] == '' or row['authors'] == 'AUTHOR NAMES ERROR':\n","        papers_df.drop(index, inplace=True)\n","papers_df.reset_index(drop=True, inplace=True)\n","\n","# join titles and abstract\n","papers_df['BERT_input'] = pd.DataFrame(papers_df['title'] + ' ' + papers_df['abstract'])\n","\n","# Load Fine-Tuned BERT Network ----\n","model = tf.saved_model.load('/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT/')\n","print('Loaded model from disk')\n","\n","# Load Label Encoder ----\n","le = LabelEncoder()\n","le.classes_ = np.load('/content/gdrive/My Drive/BiomchBERT/Data/BERT_label_encoder.npy')\n","print('Loaded Label Encoder')\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["97 Papers found\n","Loaded model from disk\n","Loaded Label Encoder\n"]}]},{"cell_type":"code","metadata":{"id":"55tVgCM--ktr","executionInfo":{"status":"ok","timestamp":1647197569739,"user_tz":420,"elapsed":3113,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}}},"source":["# Predict Paper Topic ----\n","predicted_topic = model(papers_df['BERT_input'], training=False)  # will run out of GPU memory (14GB) if predicting more than ~2000 title+abstracts at once"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvD9JQj7-2_e","executionInfo":{"status":"ok","timestamp":1647197574942,"user_tz":420,"elapsed":1909,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"d7b075b3-9873-40d6-a842-e9b80160c073"},"source":["# Determine Publications that BiomchBERT is unsure about ----\n","topics, pred_val_str = ([] for i in range(2))\n","\n","for pred_prob in predicted_topic:\n","    pred_val = np.max(pred_prob)\n","    if pred_val > 1.5 * np.sort(pred_prob)[-2]:  # Is top confidence score more than 1.5x the second best confidence score?\n","        topics.append(le.inverse_transform([np.argmax(pred_prob)])[0])\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        # pred_val_str.append(pred_val * 100)  # just report top category\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))  # report top 2 categories\n","    else:\n","        topics.append('UNKNOWN')\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))\n","        \n","papers_df['topic'] = topics\n","papers_df['pred_val'] = pred_val_str\n","\n","print('BiomchBERT is unsure about {0} papers\\n'.format(len(papers_df[papers_df['topic'] == 'UNKNOWN'])))\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BiomchBERT is unsure about 10 papers\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeacO2b3WHFu","executionInfo":{"status":"ok","timestamp":1646947556700,"user_tz":480,"elapsed":77077,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"62c1300c-e7a4-4041-c842-f2b50480cc15"},"source":["\n","# Prompt User to decide for BiomchBERT ----\n","unknown_papers = papers_df[papers_df['topic'] == 'UNKNOWN']\n","for indx, paper in unknown_papers.iterrows():\n","  print(paper['raw_title'])\n","  print(paper['journal'])\n","  print(paper['pred_val'])\n","  print()\n","  splt_str = paper['pred_val'].split(';')\n","  options = [str for pred_cls in splt_str for str in le.classes_ if (str in pred_cls)]\n"," \n"," \n","  choice = input('(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? ')\n","  print()\n","  if choice == '1':\n","    papers_df.iloc[indx]['topic'] = str(options[0])\n","  elif choice == '2':\n","    papers_df.iloc[indx]['topic'] = str(options[1])\n","  elif choice == 'o':\n","    # print all categories so you can select\n","    for i in zip(range(len(le.classes_)),le.classes_):\n","      print(i)  \n","    new_cat = input('Enter number of new class or type \"r\" to remove paper: ')\n","    print()\n","    if new_cat == 'r':\n","      papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","    else:\n","      papers_df.iloc[indx]['topic'] = le.classes_[int(new_cat)] \n","  elif choice == 'r':\n","    papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n"," \n","print('Removing {0} papers\\n'.format(len(papers_df[papers_df['topic'] == '_REMOVE_'])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unravelling the effects of ibuprofen-acetaminophen infused copper-bioglass towards the creation of root canal sealant.\n","Biomedical materials (Bristol, England)\n","49.3% TISSUE/BIOMATERIAL; 42.7% DENTAL/ORAL/FACIAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Perfluorooctane sulfonates induces neurobehavioral changes and increases dopamine neurotransmitter levels in zebrafish larvae.\n","Chemosphere\n","44.2% NEURAL; 35.8% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","[Manual medicine for the extremity joints : Successful treatment of complex symptom constellations].\n","Der Orthopade\n","46.4% REHABILITATION; 38.5% ERGONOMICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Looking to the future: Building New Paradigms in Comparative Physiology and Biomechanics.\n","The Journal of experimental biology\n","25.6% EVOLUTION/ANTHROPOLOGY; 17.2% METHODS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Scaling of fibre area and fibre glycogen concentration in the hindlimb musculature of monitor lizards: implications for locomotor performance with increasing body size.\n","The Journal of experimental biology\n","50.3% MUSCLE; 43.3% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Knee biomechanical factors associated with patellofemoral pain in recreational runners.\n","The Knee\n","35.3% JOINT/CARTILAGE; 34.9% SPORT/EXERCISE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Percutaneous fixation of intraarticular joint-depression calcaneal fractures with different screw configurations - a biomechanical human cadaveric analysis.\n","European journal of trauma and emergency surgery : official publication of the European Trauma Society\n","48.7% ORTHOPAEDICS/SURGERY; 44.0% HAND/FINGER/FOOT/TOE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Clinical Results and Radiological Bony Adaptations on a Cementless Short-Stem Prosthesis - A Comparative Study between Anatomical and Reverse Total Shoulder Arthroplasty.\n","Orthopaedics & traumatology, surgery & research : OTSR\n","49.8% ORTHOPAEDICS/SURGERY; 40.7% PROSTHETICS/ORTHOTICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Neural stem cell therapy in conjunction with curcumin loaded in niosomal nanoparticles enhanced recovery from traumatic brain injury.\n","Scientific reports\n","31.4% TRAUMA/IMPACT; 30.8% NEURAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Dexamethasone-loaded keratin films for ocular surface reconstruction.\n","Journal of materials science. Materials in medicine\n","55.6% TISSUE/BIOMATERIAL; 40.0% VISUAL/VESTIBULAR\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Does a suspensory lifestyle result in increased tensile strength? Organ-level material properties of sloth limb bones.\n","The Journal of experimental biology\n","50.9% EVOLUTION/ANTHROPOLOGY; 36.2% COMPARATIVE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Intrinsic carbon nanotube liquid crystalline elastomer photoactuators for high-definition biomechanics.\n","Materials horizons\n","35.0% TISSUE/BIOMATERIAL; 24.5% ROBOTICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Removing 5 papers\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Deqf5q7BdTAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646947594823,"user_tz":480,"elapsed":3051,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"9de89cc8-4243-44d6-8b9f-fb6460eca9ce"},"source":["# Double check that none of these papers were included in past literature updates ----\n","# load prior papers\n","# papers_df.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)  # run ONLY if there are no prior papers\n","prior_papers = pd.read_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv')\n","prior_papers.dropna(subset=['title'], inplace=True)\n","prior_papers.reset_index(drop=True, inplace=True)\n","\n","# NEED TO DO: find matching papers between current week and prior papers using Pubmed ID since titles can change from ahead of print to final version.\n","# match = papers_df['links'].split(']')[0].isin(prior_papers['links'].split(']')[0])\n","\n","match = papers_df['title'].isin(prior_papers['title'])  # boolean\n","print('Removing {0} papers found in prior literature updates\\n'.format(sum(match)))\n","# filter and check if everything accidentally was removed\n","filtered_papers_df = papers_df.drop(papers_df[match].index)\n","if filtered_papers_df.shape[0] < 1:\n","    raise ValueError('might have removed all the papers for some reason. ')\n","else:\n","    papers_df = filtered_papers_df\n","    papers_df.reset_index(drop=True, inplace=True)\n","    updated_prior_papers = pd.concat([prior_papers, papers_df], axis=0)\n","    updated_prior_papers.reset_index(drop=True, inplace=True)\n","    updated_prior_papers.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removing 20 papers found in prior literature updates\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fQKyxoBF36B","executionInfo":{"status":"ok","timestamp":1646947596102,"user_tz":480,"elapsed":128,"user":{"displayName":"Ryan Alcantara","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11016774030491622791"}},"outputId":"5170a662-8fd5-4a37-e982-5cf7ce84f93d"},"source":["# Create Text File for Biomch-L ----\n","# Compile papers grouped by topic\n","txtname = '/content/gdrive/My Drive/BiomchBERT/Updates/' + today.strftime(\"%Y-%m-%d\") + '-litupdate.txt'\n","txt = open(txtname, 'w', encoding='utf-8')\n","txt.write('[SIZE=16px][B]LITERATURE UPDATE[/B][/SIZE]\\n')\n","txt.write(days_ago_6.strftime(\"%b %d, %Y\") + ' - '+ yesterday.strftime(\"%b %d, %Y\")+'\\n')  # a week ago from yesterday.\n","txt.write(\n","    \"\"\"\n","Literature search terms: biomech* & locomot*\n","\n","Publications are classified by [URL=\"https://www.ryan-alcantara.com/projects/p88_BiomchBERT/\"]BiomchBERT[/URL], a neural network trained on past Biomch-L Literature Updates. BiomchBERT is managed by [URL=\"https://www.ryan-alcantara.com\"]Ryan Alcantara[/URL], a Postdoctoral Research Fellow at Stanford University. Each publication has a score (out of 100%) reflecting how confident BiomchBERT is that the publication belongs in a particular category (top 2 shown). If something doesn't look right, email ryan.alcantara[at]stanford.edu.\n","\n","Twitter: [URL=\"https://www.twitter.com/Ryan_Alcantara_\"]@Ryan_Alcantara_[/URL]. \n","\n","\n","    \"\"\"\n","    )\n","\n","# Write papers to text file grouped by topic ----\n","topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n","\n","for topic in topic_list:\n","    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop=True))\n","    txt.write('\\n')\n","    # TOPIC NAME (with some cleaning)\n","    if topic == '_REMOVE_':\n","      continue\n","    elif topic == 'UNKNOWN':\n","        txt.write('[SIZE=16px][B]*Papers BiomchBERT is unsure how to classify*[/B][/SIZE]\\n')\n","    elif topic == 'CARDIOVASCULAR/CARDIOPULMONARY':\n","      topic = 'CARDIOVASCULAR/PULMONARY'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'CELLULAR/SUBCELLULAR':\n","      topic = 'CELLULAR'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SURGERY':\n","      topic = 'ORTHOPAEDICS (SURGERY)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SPINE':\n","      topic = 'ORTHOPAEDICS (SPINE)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    else:\n","        txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    # HYPERLINKED PAPERS, AUTHORS, JOURNAL NAME\n","    for i, paper in enumerate(papers_subset['links']):\n","        txt.write('[B]%s[/B] ' % paper)\n","        txt.write('%s ' % papers_subset['authors'][i])\n","        txt.write('[I]%s[/I]. ' % papers_subset['journal'][i])\n","        # CONFIDENCE SCORE (BERT softmax categorical crossentropy)\n","        try:\n","            txt.write('(%.1f%%) \\n\\n' % papers_subset['pred_val'][i])\n","        except:\n","            txt.write('(%s)\\n\\n' % papers_subset['pred_val'][i]) \n","\n","txt.write('[SIZE=16px][B]*PICK OF THE WEEK*[/B][/SIZE]\\n')\n","txt.close()\n","print('Literature Update Exported for Biomch-L')\n","print('Location:', txtname)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Literature Update Exported for Biomch-L\n","Location: /content/gdrive/My Drive/BiomchBERT/Updates/2022-03-10-litupdate.txt\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"McR_o-iu7Czf"},"execution_count":null,"outputs":[]}]}