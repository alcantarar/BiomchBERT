{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"classify_papers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XJG5shp08CGC"},"source":["Uses Fine-Tuned BERT network to classify biomechanics papers from PubMed"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnZ8CI-rwNOY","executionInfo":{"status":"ok","timestamp":1610651890757,"user_tz":420,"elapsed":604,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"00e90dfe-ead3-48c0-a621-af7781313d23"},"source":["!rm /etc/localtime\r\n","!ln -s /usr/share/zoneinfo/America/Denver /etc/localtime\r\n","!date\r\n","# might need to restart runtime if timezone didn't change"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Jan 14 12:18:08 MST 2021\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6klLdde-78nI","executionInfo":{"status":"ok","timestamp":1610651999906,"user_tz":420,"elapsed":105735,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"61b2cb76-8f7e-4ddc-ba11-0c7250ff0d10"},"source":["## Install & load libraries\n","try:\n","  from official.nlp import optimization\n","except:\n","  !pip install -q -U tf-models-official\n","  from official.nlp import optimization\n","try:\n","  from Bio import Entrez\n","except:\n","  !pip install -q -U biopython\n","  from Bio import Entrez\n","try:\n","  import tensorflow_text as text\n","except:\n","  !pip install -q -U tensorflow_text\n","  import tensorflow_text as text\n","\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import tensorflow as tf\n","import string\n","import datetime\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","import tensorflow_hub as hub\n","from google.colab import drive\n","import datetime as dt\n","today = dt.date.today()\n","yesterday = today - dt.timedelta(days=1)\n","week_ago = yesterday - dt.timedelta(days=7)  # ensure overlap in pubmed search\n","days_ago_6 = yesterday - dt.timedelta(days=6) # for text output\n","# Mount Google Drive\n","drive.mount('/content/gdrive')\n","print(today)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.1MB 9.3MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[K     |████████████████████████████████| 37.6MB 74kB/s \n","\u001b[K     |████████████████████████████████| 358kB 52.7MB/s \n","\u001b[K     |████████████████████████████████| 174kB 59.1MB/s \n","\u001b[K     |████████████████████████████████| 102kB 14.7MB/s \n","\u001b[K     |████████████████████████████████| 276kB 56.8MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 54.6MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.3MB 7.0MB/s \n","\u001b[K     |████████████████████████████████| 3.4MB 9.1MB/s \n","\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Mounted at /content/gdrive\n","2021-01-14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaSczx4IuQ0Y","executionInfo":{"status":"ok","timestamp":1610652055695,"user_tz":420,"elapsed":39517,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"a63bbe24-247d-416c-aa61-635b364c0ba0"},"source":["# Define Search Criteria ----\n","def search(query):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.esearch(db='pubmed',\n","                            sort='most recent',\n","                            retmax='5000',\n","                            retmode='xml',\n","                            datetype='pdat',\n","                            # reldate=7,  # only within n days from now\n","                            mindate= min_date,\n","                            maxdate= max_date,  # for searching date range\n","                            term=query)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Perform Search and Pull Paper Titles ----\n","def fetch_details(ids):\n","    Entrez.email = 'your.email@example.com'\n","    handle = Entrez.efetch(db='pubmed',\n","                           retmode='xml',\n","                           id=ids)\n","    results = Entrez.read(handle)\n","    return results\n","\n","\n","# Make the stop words for string cleaning ----\n","def html_strip(text):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.replace('[','').replace(']','')\n","    return text\n","\n","def clean_str(text, stops):\n","    text = BeautifulSoup(text, 'lxml').text\n","    text = text.split()\n","    return ' '.join([word for word in text if word not in stops])\n","\n","stop = list(stopwords.words('english'))\n","stop_c = [string.capwords(word) for word in stop]\n","for word in stop_c:\n","    stop.append(word)\n","\n","new_stop = ['The', 'An', 'A', 'Do', 'Is', 'In', 'StringElement', \n","            'NlmCategory', 'Label', 'attributes', 'INTRODUCTION',\n","            'METHODS', 'BACKGROUND', 'RESULTS', 'CONCLUSIONS']\n","for s in new_stop:\n","    stop.append(s)\n","\n","# Search terms (can test string with Pubmed Advanced Search) ----\n","# search_results = search('(Biomech*[Title/Abstract] OR locomot*[Title/Abstract])')\n","min_date = week_ago.strftime('%m/%d/%Y')\n","max_date = yesterday.strftime('%m/%d/%Y')\n","search_results = search('(biomech*[Title/Abstract] OR locomot*[Title/Abstract] NOT opiod*[Title/Abstract] NOT pharm*[Journal] NOT mice[Title/Abstract] NOT rats[Title/Abstract] NOT elegans[Title/Abstract])')\n","id_list = search_results['IdList']\n","papers = fetch_details(id_list)\n","print(len(papers['PubmedArticle']), 'Papers found')\n","\n","titles, full_titles, keywords, authors, links, journals, abstracts = ([] for i in range(7))\n","\n","for paper in papers['PubmedArticle']:\n","    # clean and store titles, abstracts, and links\n","    t = clean_str(paper['MedlineCitation']['Article']['ArticleTitle'], \n","                  stop).replace('[','').replace(']','').capitalize()  # rm brackets that survived beautifulsoup, sentence case\n","    titles.append(t)\n","    full_titles.append(paper['MedlineCitation']['Article']['ArticleTitle'])\n","    pmid = paper['MedlineCitation']['PMID']\n","    links.append('[URL=\"https://www.ncbi.nlm.nih.gov/pubmed/{0}\"]{1}[/URL]'.format(pmid, html_strip(paper['MedlineCitation']['Article']['ArticleTitle'])))\n","    try:\n","        abstracts.append(clean_str(paper['MedlineCitation']['Article']['Abstract']['AbstractText'][0], \n","                                    stop).replace('[','').replace(']','').capitalize())  # rm brackets that survived beautifulsoup, sentence case\n","    except:\n","        abstracts.append('')\n","\n","    # clean and store authors\n","    auths = []\n","    try:\n","        for auth in paper['MedlineCitation']['Article']['AuthorList']:\n","            try:  # see if there is a last name and initials\n","                auth_name = [auth['LastName'], auth['Initials'] + ',']\n","                auth_name = ' '.join(auth_name)\n","                auths.append(auth_name)\n","            except:\n","                if 'LastName' in auth.keys():  # maybe they don't have initials\n","                    auths.append(auth['LastName'] + ',')\n","                else:  # no last name\n","                    auths.append('')\n","                    print(paper['MedlineCitation']['Article']['ArticleTitle'],\n","                          'has an issue with an author name:')\n","\n","    except:\n","        auths.append('AUTHOR NAMES ERROR')\n","        print(paper['MedlineCitation']['Article']['ArticleTitle'], 'has no author list?')\n","    # compile authors\n","    authors.append(' '.join(auths).replace('[','').replace(']',''))  # rm brackets in names\n","    # journal names\n","    journals.append(paper['MedlineCitation']['Article']['Journal']['Title'].replace('[','').replace(']',''))  # rm brackets\n","\n","    # store keywords \n","    if paper['MedlineCitation']['KeywordList'] != []:\n","        kwds = []\n","        for kw in paper['MedlineCitation']['KeywordList'][0]:\n","            kwds.append(kw[:])\n","        keywords.append(', '.join(kwds).lower())\n","    else:\n","      keywords.append('')\n","\n","# Put Titles, Abstracts, Authors, Journal, and Keywords into dataframe\n","papers_df = pd.DataFrame({'title': titles,\n","                          'keywords': keywords,\n","                          'abstract': abstracts,\n","                          'authors': authors,\n","                          'journal': journals,\n","                          'links': links,\n","                          'raw_title': full_titles,\n","                          'mindate': min_date,\n","                          'maxdate': max_date})\n","\n","\n","# remove papers with no title or no authors\n","for index, row in papers_df.iterrows():\n","    if row['title'] == '' or row['authors'] == 'AUTHOR NAMES ERROR':\n","        papers_df.drop(index, inplace=True)\n","papers_df.reset_index(drop=True, inplace=True)\n","\n","# join titles and abstract\n","papers_df['BERT_input'] = pd.DataFrame(papers_df['title'] + ' ' + papers_df['abstract'])\n","\n","# Load Fine-Tuned BERT Network ----\n","model = tf.saved_model.load('/content/gdrive/My Drive/BiomchBERT/Data/BiomchBERT/')\n","print('Loaded model from disk')\n","\n","# Load Label Encoder ----\n","le = LabelEncoder()\n","le.classes_ = np.load('/content/gdrive/My Drive/BiomchBERT/Data/BERT_label_encoder.npy')\n","print('Loaded Label Encoder')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["109 Papers found\n","Loaded model from disk\n","Loaded Label Encoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"55tVgCM--ktr","executionInfo":{"status":"ok","timestamp":1610653889389,"user_tz":420,"elapsed":650,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}}},"source":["# Predict Paper Topic ----\n","predicted_topic = model(papers_df['BERT_input'], training=False)  # will run out of GPU memory (14GB) if predicting more than ~2000 title+abstracts at once"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvD9JQj7-2_e","executionInfo":{"status":"ok","timestamp":1610654184413,"user_tz":420,"elapsed":1167,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"7d54ce45-6eff-4068-b457-a46d379f279d"},"source":["# Determine Publications that BiomchBERT is unsure about ----\n","topics, pred_val_str = ([] for i in range(2))\n","\n","for pred_prob in predicted_topic:\n","    pred_val = np.max(pred_prob)\n","    if pred_val > 1.5 * np.sort(pred_prob)[-2]:  # Is top confidence score more than 1.5x the second best confidence score?\n","        topics.append(le.inverse_transform([np.argmax(pred_prob)])[0])\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        # pred_val_str.append(pred_val * 100)  # just report top category\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))  # report top 2 categories\n","    else:\n","        topics.append('UNKNOWN')\n","        top1 = le.inverse_transform([np.argmax(pred_prob)])[0]\n","        top2 = le.inverse_transform([list(pred_prob).index([np.sort(pred_prob)[-2]])])[0]\n","        pred_val_str.append(str(np.round(pred_val * 100, 1)) + '% ' + str(top1) + '; ' + str(\n","            np.round(np.sort(pred_prob)[-2] * 100, 1)) + '% ' + str(top2))\n","        \n","papers_df['topic'] = topics\n","papers_df['pred_val'] = pred_val_str\n","\n","print('BiomchBERT is unsure about {0} papers\\n'.format(len(papers_df[papers_df['topic'] == 'UNKNOWN'])))\n"],"execution_count":94,"outputs":[{"output_type":"stream","text":["BiomchBERT is unsure about 13 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeacO2b3WHFu","executionInfo":{"status":"ok","timestamp":1610654262849,"user_tz":420,"elapsed":78132,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"2dc03b5b-3b0d-4452-900b-b679b470e039"},"source":["# Prompt User to decide for BiomchBERT ----\n","unknown_papers = papers_df[papers_df['topic'] == 'UNKNOWN']\n","for indx, paper in unknown_papers.iterrows():\n","  print(paper['raw_title'])\n","  print(paper['journal'])\n","  print(paper['pred_val'])\n","  print()\n","  splt_str = paper['pred_val'].split(';')\n","  options = [str for pred_cls in splt_str for str in le.classes_ if (str in pred_cls)]\n","\n","\n","  choice = input('(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? ')\n","  print()\n","  if choice == '1':\n","    papers_df.iloc[indx]['topic'] = str(options[0])\n","  elif choice == '2':\n","    papers_df.iloc[indx]['topic'] = str(options[1])\n","  elif choice == 'o':\n","    # print all categories so you can select\n","    for i in zip(range(len(le.classes_)),le.classes_):\n","      print(i)  \n","    new_cat = input('Enter number of new class or type \"r\" to remove paper: ')\n","    print()\n","    if new_cat == 'r':\n","      papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","    else:\n","      papers_df.iloc[indx]['topic'] = le.classes_[int(new_cat)] \n","  elif choice == 'r':\n","    papers_df.iloc[indx]['topic'] = '_REMOVE_'  # not deleted, but withheld from text file output\n","\n","print('Removing {0} papers\\n'.format(len(papers_df[papers_df['topic'] == '_REMOVE_'])))\n"],"execution_count":95,"outputs":[{"output_type":"stream","text":["Impact of Activity-Based Therapy on Respiratory Outcomes in a Medically Complex Child.\n","Children (Basel, Switzerland)\n","48.8% ERGONOMICS; 42.7% REHABILITATION\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Biogeography a key influence on distal forelimb variation in horses through the Cenozoic.\n","Proceedings. Biological sciences\n","44.8% COMPARATIVE; 36.3% EVOLUTION/ANTHROPOLOGY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","A portable pen-sized instrumentation to measure stiffness of soft tissues in vivo.\n","Scientific reports\n","54.3% METHODS; 43.3% TISSUE/BIOMATERIAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Prevalence of locomotive syndrome in Japanese patients more than 10 years after total hip arthroplasty: A cross-sectional cohort study.\n","Journal of orthopaedic science : official journal of the Japanese Orthopaedic Association\n","27.2% ORTHOPAEDICS/SURGERY; 25.1% ERGONOMICS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","The Biomechanical Effects of Augmentation With Flat Braided Suture on Dorsal Intercarpal Ligament Capsulodesis for Scapholunate Instability.\n","The Journal of hand surgery\n","47.3% TENDON/LIGAMENT; 32.8% ORTHOPAEDICS/SURGERY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Subtalar distraction arthrodesis for calcaneal malunion - comparison of structural freeze-dried versus autologous iliac bone graft.\n","Injury\n","50.2% ORTHOPAEDICS/SURGERY; 40.4% HAND/FINGER/FOOT/TOE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? o\n","\n","(0, 'BONE')\n","(1, 'BOTANY')\n","(2, 'CARDIOVASCULAR/CARDIOPULMONARY')\n","(3, 'CELLULAR/SUBCELLULAR')\n","(4, 'COMPARATIVE')\n","(5, 'DENTAL/ORAL/FACIAL')\n","(6, 'ERGONOMICS')\n","(7, 'EVOLUTION/ANTHROPOLOGY')\n","(8, 'GAIT/LOCOMOTION')\n","(9, 'HAND/FINGER/FOOT/TOE')\n","(10, 'JOINT/CARTILAGE')\n","(11, 'METHODS')\n","(12, 'MODELING')\n","(13, 'MUSCLE')\n","(14, 'NEURAL')\n","(15, 'ORTHOPAEDICS/SPINE')\n","(16, 'ORTHOPAEDICS/SURGERY')\n","(17, 'POSTURE/BALANCE')\n","(18, 'PROSTHETICS/ORTHOTICS')\n","(19, 'REHABILITATION')\n","(20, 'ROBOTICS')\n","(21, 'SPORT/EXERCISE')\n","(22, 'TENDON/LIGAMENT')\n","(23, 'TISSUE/BIOMATERIAL')\n","(24, 'TRAUMA/IMPACT')\n","(25, 'VETERINARY/AGRICULTURAL')\n","(26, 'VISUAL/VESTIBULAR')\n","Enter number of new class or type \"r\" to remove paper: 23\n","\n","Early evidence for emotional play contagion in juvenile ravens.\n","Animal cognition\n","41.9% COMPARATIVE; 34.4% VETERINARY/AGRICULTURAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Conditioned media from endothelial progenitor cells cultured in simulated microgravity promote angiogenesis and bone fracture healing.\n","Stem cell research & therapy\n","42.2% BONE; 29.0% TISSUE/BIOMATERIAL\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Human locomotion with reinforcement learning using bioinspired reward reshaping strategies.\n","Medical & biological engineering & computing\n","33.4% NEURAL; 30.3% MODELING\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","A simple and effective F0 knockout method for rapid screening of behaviour and other complex phenotypes.\n","eLife\n","37.7% NEURAL; 28.3% METHODS\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Influence of gap distance between bone and plate on structural stiffness and parallel interfragmental movement in far-cortical locking technique - a biomechanical study.\n","Computer methods in biomechanics and biomedical engineering\n","51.7% BONE; 35.9% ORTHOPAEDICS/SURGERY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 2\n","\n","Effects of Adjuvant Low-Dye Kinesio Taping, Adjuvant Sham Taping, or Extracorporeal Shockwave Therapy Alone in Plantar Fasciitis: A Randomized Double-Blind Controlled Trial.\n","International journal of clinical practice\n","40.7% REHABILITATION; 39.3% HAND/FINGER/FOOT/TOE\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? 1\n","\n","Mycoremediation of heavy metals: processes, mechanisms, and affecting factors.\n","Environmental science and pollution research international\n","34.5% ERGONOMICS; 31.1% BOTANY\n","\n","(1)st topic, (2)nd topic, (o)ther topic, or (r)emove paper? r\n","\n","Removing 2 papers\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Deqf5q7BdTAJ","executionInfo":{"status":"ok","timestamp":1610654319770,"user_tz":420,"elapsed":743,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}}},"source":["# Double check that none of these papers were included in past literature updates ----\n","# load prior papers\n","# papers_df.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)  # run ONLY if there are no prior papers\n","prior_papers = pd.read_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv')\n","prior_papers.dropna(subset=['title'], inplace=True)\n","prior_papers.reset_index(drop=True, inplace=True)\n","\n","# find matching titles between current week and prior papers\n","match = papers_df['title'].isin(prior_papers['title'])  # boolean\n","\n","# filter and check if everything accidentally was removed\n","filtered_papers_df = papers_df.drop(papers_df[match].index)\n","if filtered_papers_df.shape[0] < 1:\n","    raise ValueError('might have removed all the papers for some reason. ')\n","else:\n","    papers_df = filtered_papers_df\n","    papers_df.reset_index(drop=True, inplace=True)\n","    updated_prior_papers = pd.concat([prior_papers, papers_df], axis=0)\n","    updated_prior_papers.reset_index(drop=True, inplace=True)\n","    updated_prior_papers.to_csv('/content/gdrive/My Drive/BiomchBERT/Updates/prior_papers.csv', index=False)"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fQKyxoBF36B","executionInfo":{"status":"ok","timestamp":1610654323597,"user_tz":420,"elapsed":216,"user":{"displayName":"Ryan Alcantara","photoUrl":"","userId":"11016774030491622791"}},"outputId":"32ebba6c-28d0-4bad-b0d5-ac2932e4edd5"},"source":["# Create Text File for Biomch-L ----\n","# Compile papers grouped by topic\n","txtname = '/content/gdrive/My Drive/BiomchBERT/Updates/' + today.strftime(\"%Y-%m-%d\") + '-litupdate.txt'\n","txt = open(txtname, 'w', encoding='utf-8')\n","txt.write('[SIZE=16px][B]LITERATURE UPDATE[/B][/SIZE]\\n')\n","txt.write(days_ago_6.strftime(\"%b %d, %Y\") + ' - '+ yesterday.strftime(\"%b %d, %Y\")+'\\n')  # a week ago from yesterday.\n","txt.write(\n","    \"\"\"\n","Literature search terms: biomech* & locomot*\n","\n","Publications are classified by [URL=\"https://www.ryan-alcantara.com/projects/p88_BiomchBERT/\"]BiomchBERT[/URL], a neural network trained on past Biomch-L Literature Updates. BiomchBERT is managed by [URL=\"https://www.ryan-alcantara.com\"]Ryan Alcantara[/URL], a PhD Candidate at the University of Colorado Boulder. Each publication has a score (out of 100%) reflecting how confident BiomchBERT is that the publication belongs in a particular category (top 2 shown). If something doesn't look right, email ryan.alcantara[at]colorado.edu.\n","\n","Twitter: [URL=\"https://www.twitter.com/Ryan_Alcantara_\"]@Ryan_Alcantara_[/URL]. \n","\n","\n","    \"\"\"\n","    )\n","\n","# Write papers to text file grouped by topic ----\n","topic_list = np.unique(papers_df.sort_values('topic')['topic'])\n","\n","for topic in topic_list:\n","    papers_subset = pd.DataFrame(papers_df[papers_df.topic == topic].reset_index(drop=True))\n","    txt.write('\\n')\n","    # TOPIC NAME (with some cleaning)\n","    if topic == '_REMOVE_':\n","      continue\n","    elif topic == 'UNKNOWN':\n","        txt.write('[SIZE=16px][B]*Papers BiomchBERT is unsure how to classify*[/B][/SIZE]\\n')\n","    elif topic == 'CARDIOVASCULAR/CARDIOPULMONARY':\n","      topic = 'CARDIOVASCULAR/PULMONARY'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'CELLULAR/SUBCELLULAR':\n","      topic = 'CELLULAR'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SURGERY':\n","      topic = 'ORTHOPAEDICS (SURGERY)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    elif topic == 'ORTHOPAEDICS/SPINE':\n","      topic = 'ORTHOPAEDICS (SPINE)'\n","      txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    else:\n","        txt.write('[SIZE=16px][B]*%s*[/B][/SIZE]\\n' % topic)\n","    # HYPERLINKED PAPERS, AUTHORS, JOURNAL NAME\n","    for i, paper in enumerate(papers_subset['links']):\n","        txt.write('[B]%s[/B] ' % paper)\n","        txt.write('%s ' % papers_subset['authors'][i])\n","        txt.write('[I]%s[/I]. ' % papers_subset['journal'][i])\n","        # CONFIDENCE SCORE (BERT softmax categorical crossentropy)\n","        try:\n","            txt.write('(%.1f%%) \\n\\n' % papers_subset['pred_val'][i])\n","        except:\n","            txt.write('(%s)\\n\\n' % papers_subset['pred_val'][i]) \n","\n","txt.write('[SIZE=16px][B]*PICK OF THE WEEK*[/B][/SIZE]\\n')\n","txt.close()\n","print('Literature Update Exported for Biomch-L')\n","print('Location:', txtname)"],"execution_count":98,"outputs":[{"output_type":"stream","text":["Literature Update Exported for Biomch-L\n","Location: /content/gdrive/My Drive/BiomchBERT/Updates/2021-01-14-litupdate.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SB6hPbLLsxAz"},"source":[""],"execution_count":null,"outputs":[]}]}